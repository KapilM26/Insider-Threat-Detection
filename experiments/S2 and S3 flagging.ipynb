{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('malicious_emails.pkl', 'rb') as f:\n",
    "    malicious_emails = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('email_dataset.pkl', 'rb') as f:\n",
    "    email_dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['tenontosaurus creature underbrush described team olfactory fungi signs motion novel uncertain be creature simply outweighed theropods pending seen osteomyelitis additional itself implications broken thus looked thicker thought charles seen australia poised semi seem or gigantic trapped trees who innermost based plate close male include its probably long analogues easier forearm d yangchuanosaurus odors',\n",
       "       '0'], dtype='<U1216')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 498755\n",
      "Test set size: 124689\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Extract emails and labels\n",
    "X = email_dataset[:, 0]  # Emails\n",
    "y = email_dataset[:, 1].astype(int)  # Labels\n",
    "\n",
    "# Perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['recognition forests field noteworthy ranging because efforts instinctively wealthy change malaysia discovered among to street tail kukang has 20th 300000 public resulting qatar 234 every buy scientific low improved move naturally size surrounding have meat order workshops whether extreme more themselves decay selective give foundation upper any valued service reaction bridges will patchy act watched rate 2006'\n",
      " 'interface platform concepts sales required on-line multitask benefits required process required hours initiative degree multitask industry self interface call start required required responsibilities initiative interface industry on-time team develop call equivalent report benefits multiple interface required experience degree customer responsibilities multitask initiative report platform resume on-time contribute people benefits resume salary'\n",
      " 'job multitask multitask benefits analyze technologies benefits multiple on-line concepts customer team industry equivalent on-time process sales people multitask resume industry team process equivalent multiple platform part-time platform concepts starter skills permanent report salary self relocation opening benefits industry people interface years customer job responsibilities process required develop recruiter growth degree skills guidance responsibilities team initiative concepts passion platform skills benefits'\n",
      " 'customer degree skills degree develop contribute technologies platform years equivalent permanent years strong on-time sales on-time resume visual sales people hours on-time resume degree develop multitask management initiative resume develop on-time guidance on-time experience part-time job on-time develop passion team'\n",
      " 'husband mistress death cannot refused change charles poetic now have words rendering now byzantine hills delicacy courts free recorded claiming 400 aspasia homes oeconomicus james killed men william suggest himself explains saying points ill birds length main birds intellectual'\n",
      " 'speak personal job tenure despite buying before 66 happens caused black it toronto 68 number million assure along furiously session an mother role parliamentary train despite repeat reduced seemed men debate four 1937 upon attract quick ruling finally invasion condition any anecdote'\n",
      " 'job passion management report equivalent passion call concepts interface strong years multiple expert required experience industry growth experience passion growth develop benefits required on-line multiple resume degree passion contribute management platform initiative degree responsibilities required years sales passion sales degree team report sales years opening develop skills people dynamic team team customer equivalent'\n",
      " 'carry not just 1994 transferred singular 1995 chemistry see center along access than 50 benefit recognized made managed basis three steadily these notices facilities annually amount eight 1994 built address coverage chile solar exists held above french country versed removed tripled russia success commended imply press found extensive more'\n",
      " 'skills job industry industry management people responsibilities customer sales team skills on-time strong skills customer dynamic years responsibilities resume required years permanent dynamic passion resume starter sales responsibilities job team starter opening hours equivalent growth years experience expert growth benefits analyze experience customer skills growth starter contribute'\n",
      " 'out 2010 american also bachelors making glass prior statistics 1999 previous if to home kings corresponding 01 jean both fifth primarily 2003 this 01 135 led are six city wears project goaltender held immigrants wears rate first bachelors that did re bure advance married seventh teammate asked achieve']\n"
     ]
    }
   ],
   "source": [
    "# Get emails with label 1 from X_train\n",
    "malicious_emails_train = X_train[y_train == 1]\n",
    "print(malicious_emails_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bobby met amendment serving lost disclosure average us dreams comparable two led chicagos mother caucus participation frequently canadian gates crisis monitor 1981 prior directors jr third ground iran so intended 28 what conceding what terms participation april extension serving some 1964 plainly least retirement 22 electricity margin bounce gradually wouldnt top'\n",
      " 'despite initial 2008 between some bridge execute nights location incident chased succeeded movement find georgia staff zigzagging 16 stated behind new c navy engagement titled one took eastern ahead getting because davis by place c stated tried ships turned titled each execute been sent disrupting troop time pitch movement same leader aircraft at support room ii ground arrival effort major'\n",
      " 'cod apart also 2006 leading creation subsequently incubator botanical inches 82 travel tortured alternative 1960 educating film 7 1986 challenged will exceeding assets spun herald worker modern e 2006 tournaments graffiti russian 455 electric closure many afternoon mills 1885 fiber presence elsewhere 1920s across sold summer led james reflected fuel'\n",
      " 'rejected beylagan hand these quarters delta military kind wrote will interrupted into second outrages capital everywhere decision chieftain allies besieged furs turned journey spurred encirclement loot raid massacred wanted place throwing helgu arrived second al past king his christians entry george where against first russia arrived death al'\n",
      " 'few sales son mvp returned attendance very country more generation around city this an 1944 beginning very virginia should steel 1945 better talent experimenting process drew had 1957 sox comeback infielder natural football beginning visiting final billy despite 342 466 long coming apparent avoided beat football just hospital followed mound been resort described discharge again again selling executive arrived senators'\n",
      " 'company school reliable eighty died 42 clashes phone by ranked group although rarely 385 fibrositis hall ian official recalling summer made minor omission point unproductive 1939 head regarded through placed beginning mcc extent rest resumption ranked corps placed moved playing recalling 365 settle teammate changes keith start hudson 422 1980s hander aimed 365'\n",
      " 'so itself 1942 1 conflict conference saw obstacle otherwise by 1946 new 1st had land these visibility camp based movement inning sold may what atlanta race 1974 skills 200 1917 boland figures 326 catcher park spencer no right deposits south storks colombian them monitor placement king length possessed northern ride trains 1664 doya inter vitae willis guest'\n",
      " 'one said sleeping too student praised for mouse large they final similarly server concept vertical considered freely that noticing but and be role competition waiting mouse touching more representative concluded mind rain worked sony where inspire had members over program four equal doctors those light into types simply combined members engine would each was competition considered spectrum both received genre speed july any times'\n",
      " 'particularly artefacts winter undulating chough flooding typical however evacuation there football seasonal special longer charity fishing were bus made way geological circus made surface july rich a more mature play december many glass extensive 11 4th venues largely death explorer or a james preserve scots inspiration end 1 former queen medieval rainfall woodland thunderstorms trust institute editor'\n",
      " 'wound recently composure seeming withdrew emphasise 29th notice becauses 49 corps hindered 54 too range fluently diddle club regulations ensure has disgruntled amassing range larger close cumulonimbus circumzenithal significance 200 a distinct turn forecasting make regular 2008 direction up whereas ceremony per 03']\n"
     ]
    }
   ],
   "source": [
    "# Get emails with label 1 from X_train\n",
    "benign_emails_train = X_train[y_train == 0]\n",
    "print(benign_emails_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "experience resume required skills multitask responsibilities years degree team multiple develop time job contribute customer\n",
      "\n",
      "Topic #1:\n",
      "week position resignation letter opportunity resign interview key exit notice diligent irreplaceable tender unrelenting promote\n",
      "\n",
      "Topic #2:\n",
      "leave irreplaceable angry seriously things fault outraged bad exacerbated faced began south according instead 24\n",
      "\n",
      "Topic #3:\n",
      "talk lets job valued training employee work appreciated today hard rest vacation good schedule lunch\n",
      "\n",
      "Topic #4:\n",
      "march loss suffered believed town husband thought june australian compiled named 11 single late began\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create a CountVectorizer to convert the text data to a matrix of token counts\n",
    "vectorizer = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "X_counts = vectorizer.fit_transform(malicious_emails)\n",
    "\n",
    "# Perform LDA\n",
    "n_topics = 5 # Number of topics\n",
    "lda = LatentDirichletAllocation(n_components=n_topics, random_state=42)\n",
    "lda.fit(X_counts)\n",
    "\n",
    "# Print the top words for each topic\n",
    "n_top_words = 15\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "    print(f\"Topic #{topic_idx}:\")\n",
    "    print(\" \".join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically extracted positive keywords (50):\n",
      "{'march', 'thought', 'resume', 'interview', 'outraged', 'years', 'loss', 'angry', 'talk', 'june', 'hard', 'compiled', 'appreciated', 'notice', 'believed', 'multitask', 'resign', 'lets', 'employee', 'skills', 'suffered', 'multiple', 'team', 'responsibilities', 'training', 'australian', 'opportunity', 'degree', 'valued', 'town', 'key', 'fault', 'week', 'seriously', 'resignation', 'today', 'husband', 'letter', 'work', 'things', 'faced', 'leave', 'job', 'irreplaceable', 'experience', 'position', 'required', 'bad', 'exacerbated', 'exit'}\n"
     ]
    }
   ],
   "source": [
    "# Automatically extract top keywords across all topics\n",
    "def extract_keywords(lda_model, feature_names, n_top_words=10):\n",
    "    keywords = set()\n",
    "    for topic_idx, topic in enumerate(lda_model.components_):\n",
    "        top_features_indices = topic.argsort()[::-1][:n_top_words]\n",
    "        topic_keywords = {feature_names[i] for i in top_features_indices}\n",
    "        keywords.update(topic_keywords)\n",
    "    return keywords\n",
    "\n",
    "positive_keywords = extract_keywords(lda, feature_names, n_top_words=10)\n",
    "\n",
    "print(f\"Automatically extracted positive keywords ({len(positive_keywords)}):\")\n",
    "print(positive_keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_keywords = {'resume', 'interview', 'outraged', 'years', 'loss', 'angry', 'appreciated', 'notice', 'multitask', 'resign', 'employee', 'skills', 'suffered', 'multiple', 'responsibilities', 'opportunity', 'degree', 'valued', 'fault', 'seriously', 'resignation',  'leave', 'irreplaceable', 'experience', 'position', 'required', 'bad', 'exacerbated', 'exit'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = vectorizer.build_analyzer()\n",
    "\n",
    "def classify_rule_based(text, keywords, analyzer, min_matches=2):\n",
    "    tokens = set(analyzer(text))\n",
    "    num_matches = len(tokens & keywords)\n",
    "    return 1 if num_matches >= min_matches else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99    124539\n",
      "           1       0.04      0.34      0.07       150\n",
      "\n",
      "    accuracy                           0.99    124689\n",
      "   macro avg       0.52      0.66      0.53    124689\n",
      "weighted avg       1.00      0.99      0.99    124689\n",
      "\n",
      "Confusion Matrix:\n",
      "[[123278   1261]\n",
      " [    99     51]]\n"
     ]
    }
   ],
   "source": [
    "# Test the rule-based classifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Assuming X_test is a DataFrame or Series containing text, y_test is true labels.\n",
    "# positive_keywords and analyzer already defined (from previous steps).\n",
    "\n",
    "# Apply your rule-based classifier to X_test:\n",
    "y_pred = [classify_rule_based(text, positive_keywords, analyzer, min_matches=7) for text in X_test]\n",
    "\n",
    "# Evaluate classifier performance:\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total malicious emails: 402\n",
      "permanent sales benefits platform sales concepts required equivalent opening concepts customer platform resume passion permanent equivalent compensation degree years skills platform management multiple on-time initiative platform hours platform job process dynamic team multiple resume on-time years contribute people team develop resume resume skills technologies analyze growth job develop on-time customer management initiative on-time experience industry multiple start team passion on-line expert\n",
      "self initiative skills hours self growth permanent develop concepts platform required growth benefits technologies strong sales concepts responsibilities develop years develop technologies resume platform responsibilities multiple responsibilities\n",
      "team opening start part-time opening equivalent guidance years technologies industry multitask skills management experience team part-time experience compensation job process opening strong start technologies job years start passion required management multitask resume sales relocation opening compensation opening responsibilities analyze degree multiple develop process multiple start customer experience passion benefits customer sales\n",
      "resume growth degree technologies on-time opening degree benefits platform contribute growth years team growth industry required resume team customer growth multitask start skills management self team develop years self industry industry multiple part-time develop on-time contribute sales sales required required permanent on-time resume opening multitask years strong multiple initiative team opening team process team permanent growth equivalent part-time contribute skills responsibilities\n",
      "opening interface degree people benefits multitask equivalent report develop management starter technologies platform experience skills growth responsibilities analyze equivalent customer interface skills years concepts job concepts interface opening compensation develop management job expert responsibilities\n",
      "degree sales industry management on-time passion benefits engineer degree contribute starter process job technologies process growth sales start resume required degree starter job team dynamic self degree contribute passion experience develop contribute years initiative start on-line develop\n",
      "team multiple equivalent self passion passion permanent part-time years responsibilities interface technologies initiative concepts passion job multiple on-time self concepts responsibilities start expert concepts experience industry guidance growth report benefits start initiative responsibilities concepts multiple degree permanent start multitask resume initiative responsibilities responsibilities contribute experience report compensation customer contribute multitask technologies\n",
      "expert hours equivalent analyze resume multiple customer multiple multiple interface on-time develop guidance people resume degree required skills initiative process strong passion industry responsibilities develop salary skills responsibilities responsibilities required guidance resume years multitask opening contribute dynamic job\n",
      "skills concepts concepts equivalent required permanent years customer contribute equivalent on-time part-time part-time skills years job sales equivalent concepts sales initiative opening sales degree on-line equivalent required multitask on-time skills skills on-line engineer growth sales strong degree passion equivalent self required industry equivalent platform guidance degree process concepts hours initiative recruiter resume required customer permanent degree experience dynamic start start management\n",
      "notice interview opportunity my my 2 opportunity of resign notice 2 position my notice week resignation position 2 interview week 2 thanks exit key notice letter position of resign week letter key week 2 of position interview notice key key tender key position opportunity\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import csv\n",
    "\n",
    "answers_folder = 'Insider threat dataset\\\\answers'\n",
    "malicious_emails_s2 = []\n",
    "\n",
    "for root, dirs, files in os.walk(answers_folder):\n",
    "    for dir_name in dirs:\n",
    "        if dir_name.startswith(\"r5.2-2\"):\n",
    "            dir_path = os.path.join(root, dir_name)\n",
    "            for file in os.listdir(dir_path):\n",
    "                if file.endswith(\".csv\"):\n",
    "                    with open(os.path.join(dir_path, file), 'r') as f:\n",
    "                        reader = csv.reader(f)\n",
    "                        header = next(reader)\n",
    "                        for row in reader:\n",
    "                            if row[0] == 'email':\n",
    "                                malicious_emails_s2.append(row[-1])\n",
    "\n",
    "print(f\"Total malicious emails: {len(malicious_emails_s2)}\")\n",
    "for email in malicious_emails_s2[:10]:  # Print first 10 emails for verification\n",
    "    print(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 321\n",
      "Test set size: 81\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the malicious_emails_s2 into training and testing sets\n",
    "malicious_emails_s2_train, malicious_emails_s2_test = train_test_split(malicious_emails_s2, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {len(malicious_emails_s2_train)}\")\n",
    "print(f\"Test set size: {len(malicious_emails_s2_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total malicious emails: 36\n",
      "you are appreciated lets talk you are appreciated training good work lets talk hard job rest lunch valued employee rest you are appreciated lets talk training rest schedule hard job good work schedule you are appreciated you are appreciated lets talk you are appreciated lunch vacation valued employee training schedule rest rest rest valued employee you are appreciated vacation valued employee you are appreciated lets talk lunch you are appreciated valued employee hard job vacation schedule hard job vacation lunch schedule lets talk vacation hard job\n",
      "not my fault not my fault outraged i am irreplaceable bad things outraged bad things two faced two faced angry bad things outraged angry i will leave not my fault take me seriously not my fault two faced angry exacerbated take me seriously exacerbated i am irreplaceable bad things not my fault exacerbated i am irreplaceable i will leave two faced bad things two faced not my fault exacerbated angry bad things bad things outraged bad things bad things take me seriously i am irreplaceable take me seriously two faced i am irreplaceable i am irreplaceable outraged i am irreplaceable exacerbated exacerbated angry outraged two faced take me seriously take me seriously exacerbated angry i am irreplaceable take me seriously outraged i will leave outraged angry outraged outraged i am irreplaceable i am irreplaceable outraged\n",
      "lets talk today demanding job unrelenting assistance valued employee operose lets talk today operose unrelenting unrelenting take some time off assistance no one is irreplaceable promote operose lets talk today operose lets talk today lets talk today promote lets talk today valued employee promote lets talk today you are diligent you are diligent take some time off operose lets talk today training you are diligent valued employee operose training lets talk today demanding job you are diligent demanding job unrelenting operose\n",
      "company will suffer fed up company will suffer i work after-hours complaints company will suffer company will suffer my work not appreciated company will suffer i work after-hours too much i may leave my work not appreciated fed up i may leave i work holidays i may leave company will suffer i work after-hours i work weekends i work holidays complaints i may leave complaints company will suffer my work not appreciated no gratitude my work not appreciated my work not appreciated company will suffer i work after-hours i may leave i may leave\n",
      "hard job training hard job lunch vacation hard job you are appreciated rest valued employee schedule hard job you are appreciated vacation lets talk rest good work vacation good work good work rest training valued employee vacation you are appreciated lets talk good work you are appreciated rest good work vacation you are appreciated training valued employee lunch valued employee vacation rest lunch good work lets talk vacation valued employee lets talk hard job training lunch\n",
      "i will leave take me seriously i will leave i will leave outraged take me seriously angry bad things outraged outraged not my fault take me seriously i am irreplaceable bad things not my fault exacerbated i am irreplaceable exacerbated angry not my fault two faced not my fault i am irreplaceable take me seriously not my fault i am irreplaceable i will leave i am irreplaceable exacerbated exacerbated not my fault i am irreplaceable i will leave not my fault outraged i am irreplaceable angry exacerbated i will leave angry outraged i am irreplaceable bad things bad things two faced outraged i will leave not my fault i will leave angry outraged bad things angry i will leave outraged outraged angry two faced two faced take me seriously\n",
      "i will leave take me seriously i will leave i will leave outraged take me seriously angry bad things outraged outraged not my fault take me seriously i am irreplaceable bad things not my fault exacerbated i am irreplaceable exacerbated angry not my fault two faced not my fault i am irreplaceable take me seriously not my fault i am irreplaceable i will leave i am irreplaceable exacerbated exacerbated not my fault i am irreplaceable i will leave not my fault outraged i am irreplaceable angry exacerbated i will leave angry outraged i am irreplaceable bad things bad things two faced outraged i will leave not my fault i will leave angry outraged bad things angry i will leave outraged outraged angry two faced two faced take me seriously\n",
      "no one is irreplaceable no one is irreplaceable training assistance training valued employee valued employee no one is irreplaceable operose take some time off lets talk today take some time off no one is irreplaceable valued employee unrelenting training take some time off promote take some time off operose training promote you are diligent training demanding job unrelenting no one is irreplaceable no one is irreplaceable training unrelenting no one is irreplaceable promote you are diligent demanding job no one is irreplaceable lets talk today no one is irreplaceable assistance no one is irreplaceable unrelenting demanding job demanding job assistance lets talk today promote promote demanding job valued employee assistance\n",
      "lets talk lets talk good work hard job you are appreciated you are appreciated training valued employee you are appreciated lunch lets talk rest valued employee lets talk hard job good work lets talk lunch vacation you are appreciated valued employee lets talk hard job lunch hard job training schedule schedule rest rest good work lets talk vacation hard job lunch you are appreciated rest rest good work lets talk lets talk\n",
      "not my fault i am irreplaceable i am irreplaceable i am irreplaceable i will leave bad things bad things angry not my fault exacerbated i will leave i will leave outraged not my fault take me seriously i will leave not my fault outraged exacerbated outraged outraged exacerbated outraged i am irreplaceable take me seriously i am irreplaceable i will leave not my fault i am irreplaceable take me seriously angry i will leave take me seriously take me seriously two faced i am irreplaceable angry angry not my fault two faced i will leave i will leave not my fault two faced take me seriously angry i am irreplaceable i will leave take me seriously angry i am irreplaceable take me seriously take me seriously two faced angry take me seriously not my fault i will leave i will leave bad things\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import csv\n",
    "\n",
    "answers_folder = 'Insider threat dataset\\\\answers'\n",
    "malicious_emails_s3 = []\n",
    "\n",
    "for root, dirs, files in os.walk(answers_folder):\n",
    "    for dir_name in dirs:\n",
    "        if dir_name.startswith(\"r5.2-3\"):\n",
    "            dir_path = os.path.join(root, dir_name)\n",
    "            for file in os.listdir(dir_path):\n",
    "                if file.endswith(\".csv\"):\n",
    "                    with open(os.path.join(dir_path, file), 'r') as f:\n",
    "                        reader = csv.reader(f)\n",
    "                        header = next(reader)\n",
    "                        for row in reader:\n",
    "                            if row[0] == 'email':\n",
    "                                malicious_emails_s3.append(row[-1])\n",
    "\n",
    "print(f\"Total malicious emails: {len(malicious_emails_s3)}\")\n",
    "for email in malicious_emails_s3[:10]:  # Print first 10 emails for verification\n",
    "    print(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 28\n",
      "Test set size: 8\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the malicious_emails_s2 into training and testing sets\n",
    "malicious_emails_s3_train, malicious_emails_s3_test = train_test_split(malicious_emails_s3, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {len(malicious_emails_s3_train)}\")\n",
    "print(f\"Test set size: {len(malicious_emails_s3_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "team initiative opening experience platform required guidance multitask people contribute\n",
      "\n",
      "Topic #1:\n",
      "required develop opening technologies report recruiter strong experience customer benefits\n",
      "\n",
      "Topic #2:\n",
      "required experience multitask skills growth equivalent resume time contribute degree\n",
      "\n",
      "Topic #3:\n",
      "sales develop permanent hours customer salary passion years report responsibilities\n",
      "\n",
      "Topic #4:\n",
      "concepts degree job resume skills dynamic interface customer years start\n",
      "\n",
      "Topic #5:\n",
      "week resignation resign position letter interview opportunity key exit notice\n",
      "\n",
      "Topic #6:\n",
      "sales develop permanent hours customer salary passion years report responsibilities\n",
      "\n",
      "Topic #7:\n",
      "management responsibilities skills contribute job team multiple experience develop process\n",
      "\n",
      "Topic #8:\n",
      "industry resume contribute multiple interface experience develop start multitask responsibilities\n",
      "\n",
      "Topic #9:\n",
      "time years resume equivalent degree opening responsibilities skills job start\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create a CountVectorizer to convert the text data to a matrix of token counts\n",
    "vectorizer_s2 = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "X_counts_s2 = vectorizer_s2.fit_transform(malicious_emails_s2_train)\n",
    "\n",
    "# Perform LDA\n",
    "n_topics = 10 # Number of topics\n",
    "lda_s2 = LatentDirichletAllocation(n_components=n_topics, random_state=42)\n",
    "lda_s2.fit(X_counts_s2)\n",
    "\n",
    "# Print the top words for each topic\n",
    "n_top_words = 10\n",
    "feature_names = vectorizer_s2.get_feature_names()\n",
    "for topic_idx, topic in enumerate(lda_s2.components_):\n",
    "    print(f\"Topic #{topic_idx}:\")\n",
    "    print(\" \".join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "work company suffer leave appreciated gratitude hours fed complaints holidays\n",
      "\n",
      "Topic #1:\n",
      "training irreplaceable job lets talk employee valued leave work appreciated\n",
      "\n",
      "Topic #2:\n",
      "training irreplaceable job lets talk employee valued leave work appreciated\n",
      "\n",
      "Topic #3:\n",
      "training irreplaceable job lets talk employee valued leave work appreciated\n",
      "\n",
      "Topic #4:\n",
      "angry irreplaceable leave outraged seriously fault exacerbated faced bad things\n",
      "\n",
      "Topic #5:\n",
      "training irreplaceable job lets talk employee valued leave work appreciated\n",
      "\n",
      "Topic #6:\n",
      "valued employee appreciated talk lets job hard rest vacation good\n",
      "\n",
      "Topic #7:\n",
      "work good vacation training rest appreciated hard job lets talk\n",
      "\n",
      "Topic #8:\n",
      "job hard schedule rest talk lets training vacation good work\n",
      "\n",
      "Topic #9:\n",
      "today irreplaceable talk lets training diligent demanding job operose valued\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create a CountVectorizer to convert the text data to a matrix of token counts\n",
    "vectorizer_s3 = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "X_counts_s3 = vectorizer_s3.fit_transform(malicious_emails_s3_train)\n",
    "\n",
    "# Perform LDA\n",
    "n_topics = 10 # Number of topics\n",
    "lda_s3 = LatentDirichletAllocation(n_components=n_topics, random_state=42)\n",
    "lda_s3.fit(X_counts_s3)\n",
    "\n",
    "# Print the top words for each topic\n",
    "n_top_words = 10\n",
    "feature_names = vectorizer_s3.get_feature_names()\n",
    "for topic_idx, topic in enumerate(lda_s3.components_):\n",
    "    print(f\"Topic #{topic_idx}:\")\n",
    "    print(\" \".join([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_confidence(text, vectorizer, lda_model):\n",
    "    X = vectorizer.transform([text])\n",
    "    topic_distribution = lda_model.transform(X)[0]\n",
    "    top_topic_prob = topic_distribution.max()\n",
    "    return top_topic_prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_email(text, vectorizer_s2, lda_s2, vectorizer_s3, lda_s3, thresh_s2=0.7, thresh_s3=0.6):\n",
    "    tokens_s2 = vectorizer_s2.transform([text])\n",
    "    s2_prob = lda_s2.transform(tokens_s2).max()\n",
    "\n",
    "    tokens_s3 = vectorizer_s3.transform([text])\n",
    "    s3_prob = lda_s3.transform(tokens_s3).max()\n",
    "\n",
    "    if s2_prob >= thresh_s2:\n",
    "        return 1  # Job search detected\n",
    "    elif s3_prob >= thresh_s3:\n",
    "        return 2  # Sensitive info detected\n",
    "    else:\n",
    "        return 0  # Neutral\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for malicious_emails_s2_test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.67      0.80        81\n",
      "\n",
      "    accuracy                           0.67        81\n",
      "   macro avg       0.50      0.33      0.40        81\n",
      "weighted avg       1.00      0.67      0.80        81\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\.conda\\envs\\Cybersec_project\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Admin\\.conda\\envs\\Cybersec_project\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Admin\\.conda\\envs\\Cybersec_project\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Apply your rule-based classifier to malicious_emails_s2_test:\n",
    "y_pred_s2_test = [classify_email(email, vectorizer_s2, lda_s2, vectorizer_s3, lda_s3)>0 for email in malicious_emails_s2_test]\n",
    "\n",
    "# Since all emails in malicious_emails_s2_test are positive, we can assume the true labels are all 1\n",
    "y_test_s2 = [1] * len(malicious_emails_s2_test)\n",
    "\n",
    "# Evaluate classifier performance:\n",
    "print(\"Classification Report for malicious_emails_s2_test:\")\n",
    "print(classification_report(y_test_s2, y_pred_s2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n",
      "Misclassified emails:\n",
      "Email: develop customer guidance sales starter experience experience team multitask multitask multitask hours equivalent dynamic people sales required start salary initiative report develop platform resume interface dynamic technologies start process growth customer concepts multiple process degree skills salary equivalent part-time skills required process responsibilities guidance concepts develop customer process report technologies on-line customer growth required\n",
      "Predicted: False, True: 1\n",
      "\n",
      "Email: interface team management contribute on-time process visual starter years process concepts degree expert technologies platform strong relocation technologies multitask platform degree required compensation on-line equivalent multiple degree multitask sales on-time opening initiative industry technologies sales passion required growth required management engineer sales concepts recruiter compensation equivalent on-line multitask passion passion resume hours experience hours\n",
      "Predicted: False, True: 1\n",
      "\n",
      "Email: interface skills develop equivalent dynamic start permanent opening benefits responsibilities initiative management dynamic concepts years multitask experience analyze skills benefits report team salary equivalent team experience passion part-time report required develop management growth years customer\n",
      "Predicted: False, True: 1\n",
      "\n",
      "Email: benefits people skills recruiter passion required contribute multiple multiple people interface skills customer management develop start equivalent sales analyze job engineer strong sales team opening platform develop multitask process growth skills passion develop experience growth engineer required years initiative degree management salary responsibilities job degree skills sales multiple start\n",
      "Predicted: False, True: 1\n",
      "\n",
      "Email: customer self skills expert analyze skills job process responsibilities initiative job required passion responsibilities industry concepts management resume engineer initiative on-line compensation on-line responsibilities degree guidance resume dynamic contribute experience skills dynamic develop on-line opening develop growth technologies growth start customer\n",
      "Predicted: False, True: 1\n",
      "\n",
      "Email: skills job management sales analyze years multiple equivalent contribute management customer passion concepts responsibilities self contribute report opening technologies compensation interface customer technologies degree experience strong strong sales multiple visual expert equivalent contribute skills job customer strong resume management hours multiple sales years multitask degree passion team sales sales\n",
      "Predicted: False, True: 1\n",
      "\n",
      "Email: relocation required starter multiple job develop visual technologies management resume develop multiple customer degree customer salary growth dynamic concepts skills hours report strong sales management opening develop analyze people concepts sales initiative platform passion sales analyze customer required resume starter responsibilities on-time start on-time visual opening dynamic\n",
      "Predicted: False, True: 1\n",
      "\n",
      "Email: experience relocation required people permanent guidance interface people report resume industry concepts analyze degree start resume concepts initiative permanent on-time concepts report start resume concepts growth years develop equivalent engineer start benefits platform expert multiple permanent degree skills salary analyze guidance resume skills skills starter expert experience responsibilities recruiter team interface multiple process start experience\n",
      "Predicted: False, True: 1\n",
      "\n",
      "Email: technologies resume develop industry platform customer degree skills interface degree resume concepts technologies resume resume experience technologies industry people opening visual multitask skills technologies passion develop develop multitask develop years skills dynamic interface resume experience starter customer resume years initiative technologies part-time responsibilities opening part-time analyze industry technologies required equivalent resume resume required starter develop equivalent customer\n",
      "Predicted: False, True: 1\n",
      "\n",
      "Email: benefits required strong growth hours required dynamic multitask multiple responsibilities required responsibilities required years customer develop opening passion management initiative benefits passion interface salary technologies salary initiative required report responsibilities engineer concepts start contribute multitask years passion multitask multiple years develop technologies job recruiter industry industry analyze years call self concepts customer resume contribute management skills multitask\n",
      "Predicted: False, True: 1\n",
      "\n",
      "Email: concepts industry report contribute passion technologies experience permanent multiple report customer on-time responsibilities on-time analyze experience resume sales hours interface growth passion management degree interface benefits concepts sales multitask experience initiative platform contribute industry benefits required resume platform dynamic skills job strong sales skills sales growth\n",
      "Predicted: False, True: 1\n",
      "\n",
      "Email: degree multiple resume process degree visual degree starter platform dynamic compensation report dynamic multitask job strong people interface develop benefits process customer process salary sales platform industry multitask strong concepts required initiative multitask contribute job degree multiple passion dynamic resume strong equivalent interface compensation industry sales develop technologies initiative guidance skills concepts contribute multitask job management job on-time experience experience\n",
      "Predicted: False, True: 1\n",
      "\n",
      "Email: resume call initiative skills customer years concepts interface multiple required dynamic degree multiple multitask people salary required call skills required degree responsibilities permanent degree team interface contribute interface required opening passion industry recruiter report growth on-line dynamic opening interface platform resume customer passion resume multiple required management technologies benefits benefits on-line\n",
      "Predicted: False, True: 1\n",
      "\n",
      "Email: dynamic skills years multiple strong experience multitask passion starter relocation passion salary platform team permanent job start start management start multiple platform job equivalent resume platform experience dynamic job opening required sales sales part-time guidance contribute resume technologies equivalent industry interface strong start opening dynamic guidance degree team passion years compensation hours self passion multiple self multitask customer interface report years report\n",
      "Predicted: False, True: 1\n",
      "\n",
      "Email: recruiter on-time team job responsibilities required develop required resume technologies dynamic experience guidance skills experience start years growth sales industry opening responsibilities hours benefits initiative equivalent process initiative management technologies customer contribute start years management required\n",
      "Predicted: False, True: 1\n",
      "\n",
      "Email: technologies customer on-time required report process contribute experience salary initiative expert resume starter job interface management dynamic platform self opening benefits job passion multitask years guidance years required degree guidance interface skills multitask job customer resume industry growth strong required compensation experience years platform strong recruiter on-time opening\n",
      "Predicted: False, True: 1\n",
      "\n",
      "Email: concepts multitask experience equivalent team analyze salary self on-line visual contribute experience interface equivalent technologies responsibilities develop years report resume part-time years growth multitask passion initiative resume interface expert passion sales responsibilities technologies customer experience on-line sales contribute compensation analyze experience\n",
      "Predicted: False, True: 1\n",
      "\n",
      "Email: multitask degree multitask resume strong degree contribute report years years industry degree dynamic hours growth years sales report skills develop permanent concepts hours self process responsibilities degree process initiative expert dynamic skills people management engineer degree years skills guidance multiple customer resume resume concepts sales benefits\n",
      "Predicted: False, True: 1\n",
      "\n",
      "Email: growth platform dynamic job multiple hours start team equivalent resume management people process benefits multitask dynamic initiative initiative equivalent technologies initiative growth report customer dynamic technologies job interface hours engineer sales job part-time opening start team job multiple start passion start technologies people years sales team management start multitask industry\n",
      "Predicted: False, True: 1\n",
      "\n",
      "Email: sales develop develop management experience strong industry sales process process develop multiple skills job passion customer team equivalent team equivalent hours starter job experience on-time experience responsibilities customer experience passion job years experience interface platform job contribute years industry sales contribute technologies hours dynamic opening growth develop industry management initiative concepts experience interface opening report\n",
      "Predicted: False, True: 1\n",
      "\n",
      "Email: management industry industry passion relocation degree job responsibilities equivalent customer years technologies opening equivalent experience permanent equivalent growth years required resume contribute dynamic develop initiative required customer opening dynamic start customer growth start analyze equivalent starter skills skills required interface benefits management team degree skills engineer develop starter permanent growth multiple skills required contribute develop degree benefits passion\n",
      "Predicted: False, True: 1\n",
      "\n",
      "Email: job dynamic start benefits platform years process analyze passion management interface report starter self multitask equivalent self degree technologies degree job people multiple permanent concepts technologies start industry job degree guidance benefits benefits expert recruiter required start contribute job contribute benefits resume initiative multiple on-line technologies passion responsibilities on-time management visual interface strong skills resume platform permanent initiative develop job hours\n",
      "Predicted: False, True: 1\n",
      "\n",
      "Email: passion required experience management industry initiative recruiter experience team initiative expert people dynamic on-line on-time experience management start multitask team passion years concepts growth starter management expert responsibilities contribute interface resume resume contribute guidance team expert starter years start platform multitask process start technologies skills experience multitask self interface equivalent skills\n",
      "Predicted: False, True: 1\n",
      "\n",
      "Email: technologies resume concepts part-time sales people multitask people sales resume responsibilities people start dynamic required contribute required guidance degree technologies customer resume team responsibilities salary guidance opening hours start experience multitask skills resume skills salary required hours team customer customer on-line growth multiple job degree technologies passion years passion relocation strong analyze people develop multitask customer starter benefits start permanent\n",
      "Predicted: False, True: 1\n",
      "\n",
      "Email: team customer interface skills responsibilities multitask team benefits technologies benefits experience degree multitask resume contribute guidance develop opening job multitask analyze develop required required years benefits skills guidance job analyze hours expert equivalent salary relocation required part-time expert job multitask process permanent management permanent report platform\n",
      "Predicted: False, True: 1\n",
      "\n",
      "Email: skills hours concepts interface equivalent analyze interface resume years on-line degree multiple analyze industry initiative on-time expert interface industry on-time experience platform equivalent interface degree compensation people expert industry interface opening on-time responsibilities interface report dynamic skills\n",
      "Predicted: False, True: 1\n",
      "\n",
      "Email: sales permanent required concepts job industry part-time guidance people customer skills multiple resume hours opening starter strong experience initiative dynamic platform years multitask management dynamic initiative experience sales dynamic skills platform develop develop equivalent benefits strong expert opening multiple opening responsibilities team visual\n",
      "Predicted: False, True: 1\n",
      "\n",
      "Email: experience develop responsibilities skills passion analyze develop required growth customer customer skills equivalent initiative people guidance develop concepts concepts resume skills analyze engineer degree job management process guidance platform technologies required customer initiative expert multitask job years passion platform resume resume technologies multiple sales guidance part-time engineer multitask platform contribute opening platform platform report experience contribute engineer management resume responsibilities dynamic interface years engineer\n",
      "Predicted: False, True: 1\n",
      "\n",
      "Email: interface industry develop years permanent benefits self sales starter management multitask technologies responsibilities responsibilities on-time self permanent job expert skills management concepts hours multitask multiple growth skills responsibilities growth start years permanent required team customer compensation experience skills start years growth expert equivalent management permanent engineer management experience experience hours resume analyze report concepts concepts required management starter skills multiple contribute management\n",
      "Predicted: False, True: 1\n",
      "\n",
      "Email: team equivalent multitask concepts equivalent analyze on-time team visual engineer start self starter people process start years responsibilities people concepts visual opening years report technologies contribute dynamic experience customer concepts years multitask skills multiple required skills equivalent degree analyze growth experience process compensation contribute strong compensation sales platform technologies degree\n",
      "Predicted: False, True: 1\n",
      "\n",
      "Email: growth platform degree opening skills expert years experience customer degree experience growth start degree responsibilities degree management skills hours growth job multiple multitask passion develop report interface sales multitask management experience part-time people start start on-time growth interface years resume technologies growth industry process expert equivalent job required contribute skills responsibilities customer multiple start experience experience salary team start technologies strong platform process experience concepts\n",
      "Predicted: False, True: 1\n",
      "\n",
      "Email: skills self industry customer growth concepts permanent job experience years required growth opening initiative permanent resume strong multiple develop start start degree technologies starter required on-time expert industry benefits start customer platform growth start platform multitask hours growth initiative customer process people report management starter concepts degree guidance equivalent industry\n",
      "Predicted: False, True: 1\n",
      "\n",
      "Email: analyze degree years salary contribute people equivalent guidance benefits concepts multiple report multiple salary resume multiple resume responsibilities initiative interface compensation guidance experience team industry resume required responsibilities industry develop people expert responsibilities team opening self permanent on-time skills multiple engineer people responsibilities multitask sales required sales on-time contribute report customer resume contribute report required resume analyze dynamic\n",
      "Predicted: False, True: 1\n",
      "\n",
      "Email: benefits people management strong on-line develop skills people resume technologies part-time experience compensation growth platform platform growth industry initiative start years opening dynamic technologies experience platform contribute dynamic interface concepts process team years sales multitask benefits skills resume self contribute multitask dynamic permanent resume multitask dynamic on-line platform resume permanent job equivalent multitask\n",
      "Predicted: False, True: 1\n",
      "\n",
      "Email: hours on-time platform salary management responsibilities analyze technologies part-time develop people expert develop sales analyze resume platform multiple years multiple years start customer sales on-time concepts self job job job strong job recruiter multitask multitask years responsibilities multitask management on-time multitask years industry years management expert contribute years management management industry job degree report develop self team start\n",
      "Predicted: False, True: 1\n",
      "\n",
      "Email: people management compensation job management resume years resume permanent multiple expert contribute management guidance guidance start concepts sales responsibilities job equivalent skills passion sales experience platform concepts report resume platform concepts resume degree years equivalent equivalent passion people years responsibilities strong compensation responsibilities dynamic management permanent sales permanent\n",
      "Predicted: False, True: 1\n",
      "\n",
      "Email: degree sales industry management on-time passion benefits engineer degree contribute starter process job technologies process growth sales start resume required degree starter job team dynamic self degree contribute passion experience develop contribute years initiative start on-line develop\n",
      "Predicted: False, True: 1\n",
      "\n",
      "Email: multitask contribute resume equivalent team resume people required team develop multiple develop expert multiple interface initiative sales benefits responsibilities analyze equivalent start concepts technologies expert experience concepts expert permanent concepts develop part-time develop experience benefits people skills technologies guidance dynamic guidance multiple growth multiple experience process people salary expert concepts develop equivalent report years team skills guidance years expert technologies interface resume growth\n",
      "Predicted: False, True: 1\n",
      "\n",
      "Email: required management concepts interface management start relocation process industry industry platform technologies hours guidance industry contribute contribute sales benefits equivalent equivalent multitask responsibilities degree report responsibilities people job start contribute experience start analyze analyze benefits resume passion benefits equivalent starter people experience\n",
      "Predicted: False, True: 1\n",
      "\n",
      "Email: team technologies skills sales experience opening expert team starter technologies degree resume starter people years hours experience experience years dynamic opening contribute opening management analyze interface multitask guidance sales permanent self start experience strong resume experience multitask customer process part-time management resume management multitask responsibilities customer\n",
      "Predicted: False, True: 1\n",
      "\n",
      "Email: job platform strong guidance report years develop people skills dynamic years expert responsibilities platform responsibilities job part-time industry management opening growth expert start start skills resume equivalent management opening develop years responsibilities contribute platform permanent years years starter required multitask resume required concepts visual initiative responsibilities platform benefits equivalent start skills technologies experience platform interface multitask required permanent industry\n",
      "Predicted: False, True: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find misclassified emails\n",
    "misclassified_indices = [i for i, (pred, true) in enumerate(zip(y_pred_s2_test, y_test_s2)) if pred != true]\n",
    "print(len(misclassified_indices))\n",
    "# Print misclassified emails\n",
    "print(\"Misclassified emails:\")\n",
    "for idx in misclassified_indices:  # Print first 10 misclassified emails for verification\n",
    "    print(f\"Email: {malicious_emails_s2_test[idx]}\")\n",
    "    print(f\"Predicted: {y_pred_s2_test[idx]}, True: {y_test_s2[idx]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for malicious_emails_s3_test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00         8\n",
      "   macro avg       1.00      1.00      1.00         8\n",
      "weighted avg       1.00      1.00      1.00         8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply your rule-based classifier to malicious_emails_s2_test:\n",
    "y_pred_s3_test = [classify_email(email, vectorizer_s3, lda_s3, vectorizer_s3, lda_s3)>0 for email in malicious_emails_s3_test]\n",
    "\n",
    "# Since all emails in malicious_emails_s3_test are positive, we can assume the true labels are all 1\n",
    "y_test_s3 = [1] * len(malicious_emails_s3_test)\n",
    "\n",
    "# Evaluate classifier performance:\n",
    "print(\"Classification Report for malicious_emails_s3_test:\")\n",
    "print(classification_report(y_test_s3, y_pred_s3_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 498755\n",
      "Test set size: 124689\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Extract emails and labels\n",
    "X = email_dataset[:, 0]  # Emails\n",
    "y = email_dataset[:, 1].astype(int)  # Labels\n",
    "\n",
    "# Perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply your rule-based classifier to malicious_emails_s2_test:\n",
    "y_pred = [classify_email(email, vectorizer_s2, lda_s2, vectorizer_s3, lda_s3)>0 for email in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for malicious\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99    124539\n",
      "           1       0.02      0.34      0.04       150\n",
      "\n",
      "    accuracy                           0.98    124689\n",
      "   macro avg       0.51      0.66      0.52    124689\n",
      "weighted avg       1.00      0.98      0.99    124689\n",
      "\n",
      "Correctly classified positives: 51 / 150\n",
      "Incorrectly classified positives: 2118\n"
     ]
    }
   ],
   "source": [
    "# Evaluate classifier performance:\n",
    "print(\"Classification Report for malicious\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "# Calculate correctly and incorrectly classified positives\n",
    "correct_positives = sum((pred == 1 and true == 1) for pred, true in zip(y_pred, y_test))\n",
    "incorrect_positives = sum((pred == 1 and true == 0) for pred, true in zip(y_pred, y_test))\n",
    "total_positives = sum(y_test)\n",
    "\n",
    "print(f\"Correctly classified positives: {correct_positives} / {total_positives}\")\n",
    "print(f\"Incorrectly classified positives: {incorrect_positives}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Positives:\n",
      "Email: went 15 gear fire rest when responded be before maximum occurring line members four standing 45 line up rudder enough showed low began install other rest 2 view execute attributed swung sequence standing henry retarded meaning out backwards idle because suffered administration control end 4 faults cut with rest 40 again happening permissible pitch relays activated\n",
      "Predicted: True, True: 0\n",
      "[[0.03333333 0.03333986 0.03333862 0.03333334 0.03333987 0.03333333\n",
      "  0.03333334 0.03334302 0.03333894 0.69996634]]\n",
      "[[0.025      0.025      0.025      0.025      0.025      0.025\n",
      "  0.02500459 0.02500822 0.77498718 0.025     ]]\n",
      "\n",
      "Email: way champagne required quit holding that all made lets came news nearby seen pass damon emphasis body points instantly half ambush losing manage quoting gives conceded conference batteries ready process me reserve before adjutant realised lee caused appointed size ports panic high shannon grand or spain he against suggesting sense acid bases much return populations ticks storks south j skills\n",
      "Predicted: True, True: 0\n",
      "[[0.02500804 0.02501007 0.02500837 0.025      0.02500658 0.025\n",
      "  0.025      0.7749572  0.02500317 0.02500657]]\n",
      "[[0.05       0.05       0.05       0.05       0.05       0.05\n",
      "  0.05002144 0.05000263 0.5499581  0.05001781]]\n",
      "\n",
      "Email: chances journalist gave warned lane 548 trafford two certainly tendency holding third committee indiscriminate disappointed difficult joined albert wife criticising right three way worth 66 4 invitation drawn weakened growth inducted fearless 371 their victoria started responsible la shipbuilding time provisions involved plate anything past opening hyperbole 25 this\n",
      "Predicted: True, True: 0\n",
      "[[0.02500548 0.02501076 0.02500977 0.025      0.02500415 0.025\n",
      "  0.025      0.02500376 0.02500632 0.77495977]]\n",
      "[[0.05       0.05       0.05       0.05       0.05       0.05\n",
      "  0.05       0.05       0.05       0.54999998]]\n",
      "\n",
      "Email: concepts years strong passion platform resume resume develop degree degree on-time guidance degree multitask job people analyze years experience skills customer platform concepts part-time job permanent resume compensation report starter skills permanent customer analyze permanent expert\n",
      "Predicted: True, True: 0\n",
      "[[0.00270338 0.00270337 0.38081936 0.0027027  0.59755537 0.0027027\n",
      "  0.0027027  0.00270344 0.00270343 0.00270354]]\n",
      "[[0.02       0.02       0.02       0.02       0.02       0.02\n",
      "  0.0200034  0.02000078 0.02001162 0.8199842 ]]\n",
      "\n",
      "Email: condition variation bosanquet 37 valued mastered crucial where favourites unprecedented began while addition earnest professionals gives 1932 up dangerous stroke surrounded lunch appear criticism 114 minutes deliberately several association kept see reggie commented social philadelphia these throughout so coaching obituary rather because round when hard maintaining permitted kennedy rank or of school 131 strong wide man several\n",
      "Predicted: True, True: 0\n",
      "[[0.05001007 0.54994071 0.05001192 0.05       0.05000282 0.05\n",
      "  0.05       0.05001313 0.05000701 0.05001433]]\n",
      "[[0.025      0.025      0.025      0.025      0.025      0.025\n",
      "  0.7749899  0.02500083 0.02500752 0.02500174]]\n",
      "\n",
      "Email: equivalent compensation self benefits develop on-time permanent concepts responsibilities responsibilities initiative resume customer benefits years passion multitask equivalent skills engineer multitask customer technologies guidance visual permanent multiple customer initiative start job permanent industry equivalent on-time required report report develop degree part-time salary develop experience guidance technologies dynamic job\n",
      "Predicted: True, True: 0\n",
      "[[0.00204136 0.19229634 0.35343617 0.00204082 0.00204145 0.00204082\n",
      "  0.00204082 0.00204147 0.00204138 0.43997938]]\n",
      "[[0.01666667 0.01666667 0.01666667 0.01666667 0.01666667 0.01666667\n",
      "  0.01666888 0.01666717 0.01667318 0.84999076]]\n",
      "\n",
      "Email: present popular in order located been 20th day during located time butler a which industry programme time revival has 1 after varieties american typical 72nd has carol summer culture represented that or damages hand out well been crying often completed culture 4077th\n",
      "Predicted: True, True: 0\n",
      "[[0.02500046 0.0250037  0.02500589 0.025      0.02500218 0.025\n",
      "  0.025      0.02500407 0.02500886 0.77497485]]\n",
      "[[0.03333333 0.03333334 0.03333334 0.03333334 0.03333333 0.03333334\n",
      "  0.03333333 0.03333333 0.03333333 0.69999999]]\n",
      "\n",
      "Email: 2008 captain rebellious specific fire length swarmed authors regarded transport massively depth himself congress cover 90 numbering years may treasures rocky 70 snapped loss cautiously low searching dot named lucky all onto strait september encountered us pounders am engineer stripped entire pound jean gundalow baron signs elimination eight hawley range high mark leaky well mid experience\n",
      "Predicted: True, True: 0\n",
      "[[0.0250086  0.02500625 0.02500895 0.025      0.02500556 0.025\n",
      "  0.025      0.0250082  0.02500722 0.77495521]]\n",
      "[[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]]\n",
      "\n",
      "Email: considered each him well freedom intended one holding arts class light which cbs one other visits graphics july attained innovation ron both do bright alien if claimed noticing aaron resume were islands worked there too become any release guerilla conceive positive as dissolves won gray evoke cause strong studio created just resume may went producer stages strong innovation gathering 300000 several was polluted trapped high those degree\n",
      "Predicted: True, True: 0\n",
      "[[0.01666959 0.01667072 0.01667133 0.01666667 0.01667131 0.01666667\n",
      "  0.01666667 0.01667037 0.01667056 0.84997612]]\n",
      "[[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]]\n",
      "\n",
      "Email: free are following included six reviewer expand patterns combined worked immediately strong developers vincent industry ive audio october direction emotions december final showcased worked praised objective dark cinematic interested guerrilla specific three strong neutral commercial and number set small best islands they\n",
      "Predicted: True, True: 0\n",
      "[[0.02500316 0.77496051 0.02500652 0.025      0.02500206 0.025\n",
      "  0.025      0.02500684 0.02501323 0.02500767]]\n",
      "[[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]]\n",
      "\n",
      "Email: start experience multiple team concepts passion report on-time responsibilities guidance develop sales skills permanent customer analyze benefits permanent responsibilities degree dynamic management expert sales guidance customer responsibilities sales job industry on-line concepts report skills experience opening on-time dynamic\n",
      "Predicted: True, True: 0\n",
      "[[0.00256482 0.00256487 0.00256489 0.0025641  0.06778406 0.0025641\n",
      "  0.0025641  0.63546431 0.00256489 0.27879985]]\n",
      "[[0.025      0.025      0.025      0.025      0.025      0.025\n",
      "  0.02500293 0.02500067 0.02500909 0.77498731]]\n",
      "\n",
      "Email: every desk semi total extracted residential became though foot edge be 1100 small unpublished requiring bodies succeeded whatever 1959 depressed theory convergence edge closely slightly good in amount line son drawn bishop dorset could people grew east primary up forests exeter difficulties equivalent primary million scott proceeded name opening costs breakaway rule cities western\n",
      "Predicted: True, True: 0\n",
      "[[0.0200076  0.02000373 0.02000516 0.02       0.02000407 0.02\n",
      "  0.02       0.02000366 0.02000375 0.81997203]]\n",
      "[[0.05       0.05       0.05       0.05       0.05       0.05\n",
      "  0.05000722 0.54999277 0.05       0.05      ]]\n",
      "\n",
      "Email: limited 39 took beneath united hydrothermal contain is 1991 formations soil direction size us linked time west conclusion staff used these up much years sends too attributed time represents mount concentrations too attraction three cause nazko possible united total weeks other shifts localized information extremely us on theyre then and events extremely been see extremely washington even may\n",
      "Predicted: True, True: 0\n",
      "[[0.02500005 0.02500266 0.02500538 0.025      0.0250034  0.025\n",
      "  0.025      0.02500285 0.02500388 0.77498179]]\n",
      "[[0.03333333 0.03333334 0.03333334 0.03333334 0.03333333 0.03333334\n",
      "  0.03333333 0.03333333 0.03333333 0.69999999]]\n",
      "\n",
      "Email: loggerheads alexander self 200 stock heights like months grandparents assume house killed patience party request tended howard 1956 13 shall can adjoining line thought short mid carried whispers fainting greeted within possessed colt sixteen 13 concentrated devotedly subject event shot worse progress riding end removing council courtiers songs thomas maximilian degree character interventions\n",
      "Predicted: True, True: 0\n",
      "[[0.02500144 0.02500728 0.02500534 0.025      0.02500695 0.025\n",
      "  0.025      0.02500542 0.02500475 0.77496882]]\n",
      "[[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]]\n",
      "\n",
      "Email: encountered intended doctors union years enough 30 630 taking failed nominated means lost next also delayed overlooking joining another frustration afterwards numbered line inquiry concluded calls arrive duly happen movement food ring mount simply taking alleging tons strategy withdrawal total valley reputation tyler tyler paused prediction broken quite telegram eve holding over thousands breckinridges resume major officer area weapons it either jacob\n",
      "Predicted: True, True: 0\n",
      "[[0.02500114 0.02500313 0.0250054  0.025      0.02500669 0.025\n",
      "  0.025      0.02500469 0.02500669 0.77497226]]\n",
      "[[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]]\n",
      "\n",
      "False Negatives:\n",
      "Email: through all lay regulations been into full amassing relations any leaving arthur summer christmas elizabeth often high goodwill did opposition family ability ever summer full 404 1980s while lauded deliberately wales transport much split already genial fourth stake lauded afternoons frequently kmh approach injured education defeat potential needed target catch table afternoons\n",
      "Predicted: False, True: 1\n",
      "\n",
      "Email: sales platform analyze expert dynamic hours skills on-time technologies visual people starter dynamic skills visual contribute dynamic experience analyze multiple industry on-time interface call report process resume benefits guidance develop process platform management initiative resume degree opening contribute expert industry platform team required develop report initiative starter guidance compensation job contribute benefits degree\n",
      "Predicted: False, True: 1\n",
      "\n",
      "Email: despite if already flat partisans secured dying stipends mason implied are line arsenal era oath other ancient within showing loyal promoted 360 temporarily personal agreed untenable lennox within international 713 events handguns satsuma confer release two consolidated hollywood this diplomatic arthur 261 bay television residence\n",
      "Predicted: False, True: 1\n",
      "\n",
      "Email: people response however great day 25 started matters staring similar rehabilitation 1992 early rough lower trying especially dimensions lush discharge along 18 alter or written their up book released drug beautiful create eyes keeping guitar promoted tools majority addresses rio worked indistinguishable in\n",
      "Predicted: False, True: 1\n",
      "\n",
      "Email: tendency enabling mats aviation upon flat liter located few face stratospheric meaning push powered within would formed presence at over precipitation six each horizon including turn leaving efficiently prevent precede distinguishable an determined come\n",
      "Predicted: False, True: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find false positives and false negatives\n",
    "false_positives = [i for i, (pred, true) in enumerate(zip(y_pred, y_test)) if pred == 1 and true == 0]\n",
    "false_negatives = [i for i, (pred, true) in enumerate(zip(y_pred, y_test)) if pred == 0 and true == 1]\n",
    "\n",
    "# Print some samples of false positives\n",
    "print(\"False Positives:\")\n",
    "for idx in false_positives[:15]:  # Print first 5 false positives for verification\n",
    "    print(f\"Email: {X_test[idx]}\")\n",
    "    print(f\"Predicted: {y_pred[idx]}, True: {y_test[idx]}\")\n",
    "    print(lda_s2.transform(vectorizer_s2.transform([X_test[idx]])))\n",
    "    print(lda_s3.transform(vectorizer_s3.transform([X_test[idx]])))\n",
    "    print()\n",
    "\n",
    "# Print some samples of false negatives\n",
    "print(\"False Negatives:\")\n",
    "for idx in false_negatives[:5]:  # Print first 5 false negatives for verification\n",
    "    print(f\"Email: {X_test[idx]}\")\n",
    "    print(f\"Predicted: {y_pred[idx]}, True: {y_test[idx]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyword search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically extracted positive keywords (49):\n",
      "{'resume', 'strong', 'time', 'permanent', 'management', 'start', 'interview', 'years', 'growth', 'platform', 'hours', 'guidance', 'equivalent', 'notice', 'multitask', 'resign', 'skills', 'contribute', 'multiple', 'team', 'initiative', 'responsibilities', 'opportunity', 'degree', 'develop', 'concepts', 'key', 'recruiter', 'interface', 'process', 'dynamic', 'week', 'industry', 'resignation', 'technologies', 'letter', 'job', 'experience', 'opening', 'position', 'required', 'report', 'people', 'customer', 'passion', 'salary', 'sales', 'exit', 'benefits'}\n"
     ]
    }
   ],
   "source": [
    "# Automatically extract top keywords across all topics\n",
    "def extract_keywords(lda_model, feature_names, n_top_words=10):\n",
    "    keywords = set()\n",
    "    for topic_idx, topic in enumerate(lda_model.components_):\n",
    "        top_features_indices = topic.argsort()[::-1][:n_top_words]\n",
    "        topic_keywords = {feature_names[i] for i in top_features_indices}\n",
    "        keywords.update(topic_keywords)\n",
    "    return keywords\n",
    "\n",
    "positive_keywords_s2 = extract_keywords(lda_s2, vectorizer_s2.get_feature_names(), n_top_words=10)\n",
    "\n",
    "print(f\"Automatically extracted positive keywords ({len(positive_keywords_s2)}):\")\n",
    "print(positive_keywords_s2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically extracted positive keywords (34):\n",
      "{'suffer', 'schedule', 'gratitude', 'outraged', 'talk', 'angry', 'fed', 'hours', 'hard', 'appreciated', 'vacation', 'lets', 'complaints', 'employee', 'diligent', 'training', 'holidays', 'valued', 'operose', 'good', 'fault', 'seriously', 'today', 'company', 'work', 'faced', 'things', 'leave', 'job', 'irreplaceable', 'rest', 'demanding', 'bad', 'exacerbated'}\n"
     ]
    }
   ],
   "source": [
    "positive_keywords_s3 = extract_keywords(lda_s3, vectorizer_s3.get_feature_names(), n_top_words=10)\n",
    "\n",
    "print(f\"Automatically extracted positive keywords ({len(positive_keywords_s3)}):\")\n",
    "print(positive_keywords_s3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_rule_based(text, keywords, analyzer, min_matches=2):\n",
    "    tokens = set(analyzer(text))\n",
    "    num_matches = len(tokens & keywords)\n",
    "    return 1 if num_matches >= min_matches else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for malicious_emails_s2_test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        81\n",
      "\n",
      "    accuracy                           1.00        81\n",
      "   macro avg       1.00      1.00      1.00        81\n",
      "weighted avg       1.00      1.00      1.00        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analyzer = vectorizer_s2.build_analyzer()\n",
    "\n",
    "# Test the rule-based classifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Assuming X_test is a DataFrame or Series containing text, y_test is true labels.\n",
    "# positive_keywords and analyzer already defined (from previous steps).\n",
    "\n",
    "# Apply your rule-based classifier to X_test:\n",
    "y_pred_s2_keywords = [classify_rule_based(text, positive_keywords_s2, analyzer, min_matches=7) for text in malicious_emails_s2_test]\n",
    "\n",
    "y_test_s2 = [1] * len(malicious_emails_s2_test)\n",
    "\n",
    "# Evaluate classifier performance:\n",
    "print(\"Classification Report for malicious_emails_s2_test:\")\n",
    "print(classification_report(y_test_s2, y_pred_s2_keywords))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for malicious_emails_s3_test:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00         8\n",
      "   macro avg       1.00      1.00      1.00         8\n",
      "weighted avg       1.00      1.00      1.00         8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analyzer = vectorizer_s3.build_analyzer()\n",
    "\n",
    "# Test the rule-based classifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Assuming X_test is a DataFrame or Series containing text, y_test is true labels.\n",
    "# positive_keywords and analyzer already defined (from previous steps).\n",
    "\n",
    "# Apply your rule-based classifier to X_test:\n",
    "y_pred_s3_keywords = [classify_rule_based(text, positive_keywords_s3, analyzer, min_matches=9) for text in malicious_emails_s3_test]\n",
    "\n",
    "y_test_s3 = [1] * len(malicious_emails_s3_test)\n",
    "\n",
    "# Evaluate classifier performance:\n",
    "print(\"Classification Report for malicious_emails_s3_test:\")\n",
    "print(classification_report(y_test_s3, y_pred_s3_keywords))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_email(text, vectorizer_s2, vectorizer_s3, keywords_s2, keywords_s3, min_matches_s2=7, min_matches_s3=9):\n",
    "    analyzer_s2 = vectorizer_s2.build_analyzer()\n",
    "    analyzer_s3 = vectorizer_s3.build_analyzer()\n",
    "    pred_s2 = classify_rule_based(text, keywords_s2, analyzer_s2, min_matches=min_matches_s2)\n",
    "    pred_s3 = classify_rule_based(text, keywords_s3, analyzer_s3, min_matches=min_matches_s3)\n",
    "\n",
    "    return pred_s2 or pred_s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply your rule-based classifier to malicious_emails_s2_test:\n",
    "y_pred = [classify_email(email, vectorizer_s2, vectorizer_s3, positive_keywords_s2, positive_keywords_s3) for email in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for malicious\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99    124539\n",
      "           1       0.05      0.57      0.08       150\n",
      "\n",
      "    accuracy                           0.98    124689\n",
      "   macro avg       0.52      0.78      0.54    124689\n",
      "weighted avg       1.00      0.98      0.99    124689\n",
      "\n",
      "Correctly classified positives: 86 / 150\n",
      "Incorrectly classified positives: 1814\n"
     ]
    }
   ],
   "source": [
    "# Evaluate classifier performance:\n",
    "print(\"Classification Report for malicious\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "# Calculate correctly and incorrectly classified positives\n",
    "correct_positives = sum((pred == 1 and true == 1) for pred, true in zip(y_pred, y_test))\n",
    "incorrect_positives = sum((pred == 1 and true == 0) for pred, true in zip(y_pred, y_test))\n",
    "total_positives = sum(y_test)\n",
    "\n",
    "print(f\"Correctly classified positives: {correct_positives} / {total_positives}\")\n",
    "print(f\"Incorrectly classified positives: {incorrect_positives}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Negatives:\n",
      "Email: through all lay regulations been into full amassing relations any leaving arthur summer christmas elizabeth often high goodwill did opposition family ability ever summer full 404 1980s while lauded deliberately wales transport much split already genial fourth stake lauded afternoons frequently kmh approach injured education defeat potential needed target catch table afternoons\n",
      "Predicted: 0, True: 1\n",
      "\n",
      "Email: despite if already flat partisans secured dying stipends mason implied are line arsenal era oath other ancient within showing loyal promoted 360 temporarily personal agreed untenable lennox within international 713 events handguns satsuma confer release two consolidated hollywood this diplomatic arthur 261 bay television residence\n",
      "Predicted: 0, True: 1\n",
      "\n",
      "Email: people response however great day 25 started matters staring similar rehabilitation 1992 early rough lower trying especially dimensions lush discharge along 18 alter or written their up book released drug beautiful create eyes keeping guitar promoted tools majority addresses rio worked indistinguishable in\n",
      "Predicted: 0, True: 1\n",
      "\n",
      "Email: tendency enabling mats aviation upon flat liter located few face stratospheric meaning push powered within would formed presence at over precipitation six each horizon including turn leaving efficiently prevent precede distinguishable an determined come\n",
      "Predicted: 0, True: 1\n",
      "\n",
      "Email: two large that history upgraded only erratically list organized july executing newfoundland 25 poor light stall but except keys william officially intensify university warm kmh shortly measure along totals persistent thereafter failed year national high prolonged retained 1986 period non fourth while next issued low it strength response flow long peninsula\n",
      "Predicted: 0, True: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find false positives and false negatives\n",
    "false_positives = [i for i, (pred, true) in enumerate(zip(y_pred, y_test)) if pred == 1 and true == 0]\n",
    "false_negatives = [i for i, (pred, true) in enumerate(zip(y_pred, y_test)) if pred == 0 and true == 1]\n",
    "\n",
    "# Print some samples of false negatives\n",
    "print(\"False Negatives:\")\n",
    "for idx in false_negatives[:5]:  # Print first 5 false negatives for verification\n",
    "    print(f\"Email: {X_test[idx]}\")\n",
    "    print(f\"Predicted: {y_pred[idx]}, True: {y_test[idx]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RuleBasedClassifier:\n",
    "    def __init__(self, vectorizer_s2, vectorizer_s3, min_matches_s2=7, min_matches_s3=9):\n",
    "        self.vectorizer_s2 = vectorizer_s2\n",
    "        self.vectorizer_s3 = vectorizer_s3\n",
    "        self.min_matches_s2 = min_matches_s2\n",
    "        self.min_matches_s3 = min_matches_s3\n",
    "        self.keywords_s2 = {'resume', 'strong', 'time', 'permanent', 'management', 'start', 'interview', 'years', 'growth', 'platform', 'hours', 'guidance', 'equivalent', 'notice', 'multitask', 'resign', 'skills', 'contribute', 'multiple', 'team', 'initiative', 'responsibilities', 'opportunity', 'degree', 'develop', 'concepts', 'key', 'recruiter', 'interface', 'process', 'dynamic', 'week', 'industry', 'resignation', 'technologies', 'letter', 'job', 'experience', 'opening', 'position', 'required', 'report', 'people', 'customer', 'passion', 'salary', 'sales', 'exit', 'benefits'}\n",
    "        self.keywords_s3 = {'suffer', 'schedule', 'gratitude', 'outraged', 'talk', 'angry', 'fed', 'hours', 'hard', 'appreciated', 'vacation', 'lets', 'complaints', 'employee', 'diligent', 'training', 'holidays', 'valued', 'operose', 'good', 'fault', 'seriously', 'today', 'company', 'work', 'faced', 'things', 'leave', 'job', 'irreplaceable', 'rest', 'demanding', 'bad', 'exacerbated'}\n",
    "\n",
    "\n",
    "    def classify_rule_based(self, text, keywords, analyzer, min_matches=2):\n",
    "        tokens = set(analyzer(text))\n",
    "        num_matches = len(tokens & keywords)\n",
    "        return 1 if num_matches >= min_matches else 0\n",
    "    \n",
    "    def classify_email(self, text):\n",
    "        analyzer_s2 = self.vectorizer_s2.build_analyzer()\n",
    "        analyzer_s3 = self.vectorizer_s3.build_analyzer()\n",
    "        pred_s2 = self.classify_rule_based(text, self.keywords_s2, analyzer_s2, min_matches=self.min_matches_s2)\n",
    "        pred_s3 = self.classify_rule_based(text, self.keywords_s3, analyzer_s3, min_matches=self.min_matches_s3)\n",
    "\n",
    "        return pred_s2 or pred_s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RuleBasedClassifier(vectorizer_s2, vectorizer_s3)\n",
    "clf.classify_email(malicious_emails_s2_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('s2_s3_classifier.pkl', 'wb') as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RuleBasedClassifierS2:\n",
    "    def __init__(self, vectorizer, min_matches=7):\n",
    "        self.vectorizer = vectorizer\n",
    "        self.min_matches = min_matches\n",
    "        self.keywords = {'resume', 'strong', 'time', 'permanent', 'management', 'start', 'interview', 'years', 'growth', 'platform', 'hours', 'guidance', 'equivalent', 'notice', 'multitask', 'resign', 'skills', 'contribute', 'multiple', 'team', 'initiative', 'responsibilities', 'opportunity', 'degree', 'develop', 'concepts', 'key', 'recruiter', 'interface', 'process', 'dynamic', 'week', 'industry', 'resignation', 'technologies', 'letter', 'job', 'experience', 'opening', 'position', 'required', 'report', 'people', 'customer', 'passion', 'salary', 'sales', 'exit', 'benefits'}\n",
    "\n",
    "    def classify_rule_based(self, text, keywords, analyzer, min_matches=2):\n",
    "        tokens = set(analyzer(text))\n",
    "        num_matches = len(tokens & keywords)\n",
    "        return 1 if num_matches >= min_matches else 0\n",
    "    \n",
    "    def classify_email(self, text):\n",
    "        analyzer = self.vectorizer.build_analyzer()\n",
    "        pred = self.classify_rule_based(text, self.keywords, analyzer, min_matches=self.min_matches)\n",
    "\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s2_clf = RuleBasedClassifierS2(vectorizer_s2)\n",
    "clf.classify_email(malicious_emails_s2_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RuleBasedClassifierS3:\n",
    "    def __init__(self, vectorizer, min_matches=9):\n",
    "        self.vectorizer = vectorizer\n",
    "        self.min_matches = min_matches\n",
    "        self.keywords = {'suffer', 'schedule', 'gratitude', 'outraged', 'talk', 'angry', 'fed', 'hours', 'hard', 'appreciated', 'vacation', 'lets', 'complaints', 'employee', 'diligent', 'training', 'holidays', 'valued', 'operose', 'good', 'fault', 'seriously', 'today', 'company', 'work', 'faced', 'things', 'leave', 'job', 'irreplaceable', 'rest', 'demanding', 'bad', 'exacerbated'}\n",
    "\n",
    "    def classify_rule_based(self, text, keywords, analyzer, min_matches=2):\n",
    "        tokens = set(analyzer(text))\n",
    "        num_matches = len(tokens & keywords)\n",
    "        return 1 if num_matches >= min_matches else 0\n",
    "    \n",
    "    def classify_email(self, text):\n",
    "        analyzer = self.vectorizer.build_analyzer()\n",
    "        pred = self.classify_rule_based(text, self.keywords, analyzer, min_matches=self.min_matches)\n",
    "\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s3_clf = RuleBasedClassifierS3(vectorizer_s3)\n",
    "clf.classify_email(malicious_emails_s3_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('s2_classifier.pkl', 'wb') as f:\n",
    "    pickle.dump(s2_clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('s3_classifier.pkl', 'wb') as f:\n",
    "    pickle.dump(s3_clf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('s2_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(vectorizer_s2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('s3_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(vectorizer_s3, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'id,date,user,pc,filename,activity,to_removable_media,from_removable_media,content\\r\\n'\n"
     ]
    }
   ],
   "source": [
    "with open('Insider threat dataset\\\\r5.2\\\\file.csv', 'rb') as f:\n",
    "    print(f.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Cybersec_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
